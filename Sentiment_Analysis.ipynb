{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X5bIYeALxTYs"
      },
      "outputs": [],
      "source": [
        "#Sentiment analysis in NLP is a technique to determine the emotional tone behind the body of the text\n",
        "# 1. Rule Based Systems (Core Rules | Data Mining Based Systems)\n",
        "# 2. Transformer Based Systems\n",
        "\n",
        "\n",
        "# As per NLP, there exists three types of sentiment\n",
        "# 1. Positive Sentiment\n",
        "# 2. Negatice Sentiment\n",
        "# 3. Neutral Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oEl71ArLx193"
      },
      "outputs": [],
      "source": [
        "#Basic Rule Based System | Domain Based approach (Using language for understanding the sentence's sentiment)\n",
        "\n",
        "#Step1: Create dictionaries containing positive and negative words | LEXICON\n",
        "\n",
        "positiveWords = [\"good\",\"happy\",\"excellent\",\"great\",\"positive\",\"fortunate\"]\n",
        "negativeWords = [\"bad\",\"sad\",\"poor\",\"negative\",\"unfortunate\",\"terrible\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rQzMVkUjyw84"
      },
      "outputs": [],
      "source": [
        "#Simple Analyser function to analyse the sentiment of the given text data\n",
        "\n",
        "def ruleBasedSimpleTextSentimentAnalyser(textData):\n",
        "  #Normalization\n",
        "\n",
        "  textData = textData.lower()\n",
        "\n",
        "  #Initialize sentiment score\n",
        "\n",
        "  positiveCount = 0\n",
        "  negativeCount = 0\n",
        "\n",
        "  #Tokenize the text into words\n",
        "  words = textData.split()\n",
        "\n",
        "  #Check each word with my dictionary to identify number of positive and negative words\n",
        "\n",
        "  for word in words:\n",
        "    if word in positiveWords:\n",
        "      positiveCount += 1\n",
        "    elif word in negativeWords:\n",
        "      negativeCount += 1\n",
        "\n",
        "  #Determine sentiment\n",
        "\n",
        "  if positiveCount > negativeCount:\n",
        "    return \"Positive\"\n",
        "  elif negativeCount > positiveCount:\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WiMVWy04zFRw",
        "outputId": "0275ff4e-ad1c-4319-db2c-94a950499191"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Positive'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ruleBasedSimpleTextSentimentAnalyser(\"This product is great and works perfectly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vY3kVQS9z8oc",
        "outputId": "b52ed4e0-4e6f-413c-902b-8f9f7e469177"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Positive'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputData = input(\"Enter text: \")\n",
        "ruleBasedSimpleTextSentimentAnalyser(inputData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4aXYlYG11Y87"
      },
      "outputs": [],
      "source": [
        "#VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
        "#\n",
        "# VADER uses rule-based approach with predefined LEXICON which maps words to their sentiment intensity scores.\n",
        "# It considers the following:\n",
        "# 1. Words\n",
        "# 2. Exclamation points\n",
        "# 3. Emphasize on Capital letter\n",
        "# 4. Negation words\n",
        "# 5. Level of the sentiment (Degree Modifiers) ---- extremely happy, super excited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6xMCDpnK3FkA"
      },
      "outputs": [],
      "source": [
        "#VADER Scoring System\n",
        "# VADER assigns each word in a textdata a score between -4 to +4\n",
        "# Positive words have score close to +4\n",
        "# Negative words have score close to -4\n",
        "# Neutral words have score close to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o9_h56HB3dkZ"
      },
      "outputs": [],
      "source": [
        "#Metrics in VADER system\n",
        "# 1. Positive Score : Propotion of the text with positive sentiment\n",
        "# 2. Negative Score: Proportion of text with negative sentiment\n",
        "# 3. Neutral Score : Proportion of text with neutral sentiment\n",
        "# 4. Compound Score : Overall SENIMENT score (range from -1(most negative) to +1(Most positive))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeLz7jiW3_7A",
        "outputId": "3afea1f2-7fe8-4791-ce0c-f8f70475a9b8"
      },
      "outputs": [],
      "source": [
        "import vaderSentiment\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/micha/yelp.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubVjrl--4CM2",
        "outputId": "ebe8feba-0892-460c-c124-93c7edc4f748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "\n",
        "analyser.polarity_scores(\"Not bad at all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m_HJ1PjM4V8P"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def senimentClassifierUsingVader(textData):\n",
        "  analyser = SentimentIntensityAnalyzer()\n",
        "  scores = analyser.polarity_scores(textData)\n",
        "  compoundScore = scores['compound']\n",
        "\n",
        "  if compoundScore >= 0.05:\n",
        "    return \"Positive\"\n",
        "  elif compoundScore <= -0.05:\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rtHRvnZ74wUp",
        "outputId": "0e5fbb65-203a-442f-cd52-05244cdbe684"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msenimentClassifierUsingVader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead\n",
            "Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36msenimentClassifierUsingVader\u001b[1;34m(textData)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msenimentClassifierUsingVader\u001b[39m(textData):\n\u001b[0;32m      4\u001b[0m   analyser \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[1;32m----> 5\u001b[0m   scores \u001b[38;5;241m=\u001b[39m \u001b[43manalyser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtextData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m   compoundScore \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m compoundScore \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\vaderSentiment\\vaderSentiment.py:269\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    266\u001b[0m         sentiments\u001b[38;5;241m.\u001b[39mappend(valence)\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     sentiments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentiment_valence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentitext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_but_check(words_and_emoticons, sentiments)\n\u001b[0;32m    273\u001b[0m valence_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_valence(sentiments, text)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\vaderSentiment\\vaderSentiment.py:314\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.sentiment_valence\u001b[1;34m(self, valence, sentitext, item, i, sentiments)\u001b[0m\n\u001b[0;32m    312\u001b[0m             valence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_negation_check(valence, words_and_emoticons, start_i, i)\n\u001b[0;32m    313\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 314\u001b[0m                 valence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_special_idioms_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_and_emoticons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     valence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_least_check(valence, words_and_emoticons, i)\n\u001b[0;32m    317\u001b[0m sentiments\u001b[38;5;241m.\u001b[39mappend(valence)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\vaderSentiment\\vaderSentiment.py:349\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer._special_idioms_check\u001b[1;34m(valence, words_and_emoticons, i)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_special_idioms_check\u001b[39m(valence, words_and_emoticons, i):\n\u001b[1;32m--> 349\u001b[0m     words_and_emoticons_lower \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(w)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words_and_emoticons]\n\u001b[0;32m    350\u001b[0m     onezero \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(words_and_emoticons_lower[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], words_and_emoticons_lower[i])\n\u001b[0;32m    352\u001b[0m     twoonezero \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(words_and_emoticons_lower[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    353\u001b[0m                                       words_and_emoticons_lower[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], words_and_emoticons_lower[i])\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "data['sentiment'] = senimentClassifierUsingVader(data['text'])\n",
        "data.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzvKkQ7n5Tdc"
      },
      "outputs": [],
      "source": [
        "#https://github.com/cjhutto/vaderSentiment/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = data.iloc[:,[4]].values\n",
        "label = data.iloc[:,10].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "def textPreprocessing(document):\n",
        "  #Remove Punctuations\n",
        "  processedData = ''.join([char for char in document if char not in string.punctuation])\n",
        "  #Seperate words from document and normalize it\n",
        "  wordsInLowerCase = [word.lower() for word in processedData.split(\" \")]\n",
        "  #Generate Vocab\n",
        "  return [word for word in wordsInLowerCase if word not in stopwords.words('english')]\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "wordVector = CountVectorizer(analyzer=textPreprocessing)\n",
        "finalWordVectorVocab = wordVector.fit(features)\n",
        "bagOfWords = finalWordVectorVocab.transform(features)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(bagOfWords,\n",
        "                                                 label,\n",
        "                                                 test_size=0.2,\n",
        "                                                 random_state=6)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelLogisticRegression = LogisticRegression()\n",
        "modelLogisticRegression.fit(X_train,y_train)\n",
        "print(\"Train Score is {} and Test Score is {}\".format(modelLogisticRegression.score(X_train,y_train), modelLogisticRegression.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KOT4shK8wvh"
      },
      "outputs": [],
      "source": [
        "# yelp dataset (Day7 assignment folder)\n",
        "# Using Vader create a new column named sentiment and find sentiment for each text/review and store the same in the sentiment column\n",
        "# Create a ML model for performing sentimental analysis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
